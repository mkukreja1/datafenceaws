{
	"metadata": {
		"kernelspec": {
			"name": "glue_pyspark",
			"display_name": "Glue PySpark",
			"language": "python"
		},
		"language_info": {
			"name": "Python_Glue_Session",
			"mimetype": "text/x-python",
			"codemirror_mode": {
				"name": "python",
				"version": 3
			},
			"pygments_lexer": "python3",
			"file_extension": ".py"
		}
	},
	"nbformat_minor": 4,
	"nbformat": 4,
	"cells": [
		{
			"cell_type": "markdown",
			"source": "\n# Glue Studio Notebook\nYou are now running a **Glue Studio** notebook; before you can start using your notebook you *must* start an interactive session.\n\n## Available Magics\n|          Magic              |   Type       |                                                                        Description                                                                        |\n|-----------------------------|--------------|-----------------------------------------------------------------------------------------------------------------------------------------------------------|\n| %%configure                 |  Dictionary  |  A json-formatted dictionary consisting of all configuration parameters for a session. Each parameter can be specified here or through individual magics. |\n| %profile                    |  String      |  Specify a profile in your aws configuration to use as the credentials provider.                                                                          |\n| %iam_role                   |  String      |  Specify an IAM role to execute your session with.                                                                                                        |\n| %region                     |  String      |  Specify the AWS region in which to initialize a session.                                                                                                 |\n| %session_id                 |  String      |  Returns the session ID for the running session.                                                                                                          |\n| %connections                |  List        |  Specify a comma separated list of connections to use in the session.                                                                                     |\n| %additional_python_modules  |  List        |  Comma separated list of pip packages, s3 paths or private pip arguments.                                                                                 |\n| %extra_py_files             |  List        |  Comma separated list of additional Python files from S3.                                                                                                 |\n| %extra_jars                 |  List        |  Comma separated list of additional Jars to include in the cluster.                                                                                       |\n| %number_of_workers          |  Integer     |  The number of workers of a defined worker_type that are allocated when a job runs. worker_type must be set too.                                          |\n| %glue_version               |  String      |  The version of Glue to be used by this session. Currently, the only valid options are 2.0 and 3.0 (eg: %glue_version 2.0).                               |\n| %security_config            |  String      |  Define a security configuration to be used with this session.                                                                                            |\n| %sql                        |  String      |  Run SQL code. All lines after the initial %%sql magic will be passed as part of the SQL code.                                                            |\n| %streaming                  |  String      |  Changes the session type to Glue Streaming.                                                                                                              |\n| %etl                        |  String      |  Changes the session type to Glue ETL.                                                                                                                    |\n| %status                     |              |  Returns the status of the current Glue session including its duration, configuration and executing user / role.                                          |\n| %stop_session               |              |  Stops the current session.                                                                                                                               |\n| %list_sessions              |              |  Lists all currently running sessions by name and ID.                                                                                                     |\n| %worker_type                |  String      |  Standard, G.1X, *or* G.2X. number_of_workers must be set too. Default is G.1X.                                                                           |\n| %spark_conf                 |  String      |  Specify custom spark configurations for your session. E.g. %spark_conf spark.serializer=org.apache.spark.serializer.KryoSerializer.                      |",
			"metadata": {
				"editable": false,
				"deletable": false,
				"trusted": true
			}
		},
		{
			"cell_type": "code",
			"source": "%glue_version 3.0\n%spark_conf spark.sql.catalog.spark_catalog=org.apache.spark.sql.delta.catalog.DeltaCatalog\n%spark_conf spark.sql.extensions=io.delta.sql.DeltaSparkSessionExtension\n%number_of_workers 2\n\n%%configure\n{\n  \"--datalake-formats\": \"delta\"\n}\n\n",
			"metadata": {
				"trusted": true
			},
			"execution_count": 6,
			"outputs": [
				{
					"name": "stdout",
					"text": "Welcome to the Glue Interactive Sessions Kernel\nFor more information on available magic commands, please type %help in any new cell.\n\nPlease view our Getting Started page to access the most up-to-date information on the Interactive Sessions kernel: https://docs.aws.amazon.com/glue/latest/dg/interactive-sessions.html\nInstalled kernel version: 0.37.0 \nSetting Glue version to: 3.0\nPrevious Spark configuration: None\nSetting new Spark configuration to: spark.sql.catalog.spark_catalog=org.apache.spark.sql.delta.catalog.DeltaCatalog\nPrevious Spark configuration: spark.sql.catalog.spark_catalog=org.apache.spark.sql.delta.catalog.DeltaCatalog\nSetting new Spark configuration to: spark.sql.extensions=io.delta.sql.DeltaSparkSessionExtension\nPrevious number of workers: 5\nSetting new number of workers to: 2\nThe following configurations have been updated: {'--datalake-formats': 'delta'}\n",
					"output_type": "stream"
				}
			]
		},
		{
			"cell_type": "code",
			"source": "import sys\nfrom awsglue.transforms import *\nfrom awsglue.utils import getResolvedOptions\nfrom pyspark.context import SparkContext\nfrom awsglue.context import GlueContext\nfrom awsglue.job import Job\n\nfrom delta.tables import *\nfrom pyspark.sql.types import StructType, StructField, IntegerType, StringType, array, ArrayType, DateType, TimestampType, FloatType\n\nsc = SparkContext.getOrCreate()\nglueContext = GlueContext(sc)\nspark = glueContext.spark_session\njob = Job(glueContext)",
			"metadata": {
				"editable": true,
				"trusted": true
			},
			"execution_count": 1,
			"outputs": [
				{
					"name": "stdout",
					"text": "Authenticating with environment variables and user-defined glue_role_arn: arn:aws:iam::175908995626:role/glue-role\nTrying to create a Glue session for the kernel.\nWorker Type: G.1X\nNumber of Workers: 2\nSession ID: c15ab862-78f8-4788-8a7a-dbb73cc37045\nJob Type: glueetl\nApplying the following default arguments:\n--glue_kernel_version 0.37.0\n--enable-glue-datacatalog true\n--conf spark.sql.extensions=io.delta.sql.DeltaSparkSessionExtension\n--datalake-formats delta\nWaiting for session c15ab862-78f8-4788-8a7a-dbb73cc37045 to get into ready status...\nSession c15ab862-78f8-4788-8a7a-dbb73cc37045 has been created.\n\n",
					"output_type": "stream"
				}
			]
		},
		{
			"cell_type": "code",
			"source": "ORDERS_SCHEMA =[\n    ('order_number', StringType()),\n    ('customer_id', StringType()),\n    ('product_id', StringType()),\n    ('order_date', StringType()),\n    ('units', StringType()),    \n    ('sale_price', StringType()),\n    ('currency', StringType()),\n    ('order_mode', StringType()),\n    ('updated_at', StringType())\n]\nfields = [StructField(*field) for field in ORDERS_SCHEMA]\nschema = StructType(fields)\n\ndf_read_data_full = spark.read.csv(\"s3://aws-analytics-course/bronze/dms/sales/store_orders/LOAD00000001.csv\",schema=schema )\ndf_read_data_full.show()",
			"metadata": {
				"trusted": true
			},
			"execution_count": 2,
			"outputs": [
				{
					"name": "stdout",
					"text": "+------------+-----------+----------+----------+----------+----------+--------+----------+----------+\n|order_number|customer_id|product_id|order_date|     units|sale_price|currency|order_mode|updated_at|\n+------------+-----------+----------+----------+----------+----------+--------+----------+----------+\n|           I|          1|       212|         5|02/03/2019|        10|   11.60|       USD|       NEW|\n|           I|          2|      1940|        10|06/24/2020|         8|   72.31|       USD|       NEW|\n|           I|          3|        60|         6|02/11/2019|         4|   24.82|       INR|       NEW|\n|           I|          4|      2776|         6|05/20/2018|         4|   20.91|       USD|       NEW|\n|           I|          5|       409|         9|07/05/2019|         5|   98.41|       INR|       NEW|\n|           I|          6|       978|         6|12/16/2020|         1|    6.90|       USD|       NEW|\n|           I|          7|      2904|         6|01/04/2021|         1|   71.56|       EUR|       NEW|\n|           I|          8|      1269|         3|08/11/2018|         6|   47.67|       USD|       NEW|\n|           I|          9|      2628|         5|01/16/2017|         1|   59.05|       EUR|       NEW|\n|           I|         10|      1672|         8|08/01/2020|         3|   43.42|       USD|       NEW|\n|           I|         11|      2666|         5|05/25/2018|         5|   43.98|       EUR|       NEW|\n|           I|         12|      1521|         9|02/21/2019|         1|    9.70|       EUR|       NEW|\n|           I|         13|      2681|         1|05/12/2017|         3|    7.69|       CAD|       NEW|\n|           I|         14|      1485|         3|07/21/2020|         3|   38.58|       EUR|       NEW|\n|           I|         15|      2550|         6|08/14/2020|         4|    5.51|       CAD|       NEW|\n|           I|         16|       259|         7|07/04/2017|         1|   71.70|       USD|       NEW|\n|           I|         17|      1143|         1|10/31/2017|         5|    0.32|       EUR|       NEW|\n|           I|         18|       185|         2|10/25/2017|         3|   98.92|       USD|       NEW|\n|           I|         19|      1819|         2|02/26/2021|         2|   52.88|       CAD|       NEW|\n|           I|         20|       110|         1|08/31/2020|         7|   39.11|       INR|       NEW|\n+------------+-----------+----------+----------+----------+----------+--------+----------+----------+\nonly showing top 20 rows\n",
					"output_type": "stream"
				}
			]
		},
		{
			"cell_type": "code",
			"source": "df_read_data_full.write \\\n    .format(\"delta\") \\\n    .save(\"s3://aws-analytics-course/temp/store_orders\") ",
			"metadata": {
				"trusted": true
			},
			"execution_count": 3,
			"outputs": [
				{
					"name": "stdout",
					"text": "\n",
					"output_type": "stream"
				}
			]
		},
		{
			"cell_type": "code",
			"source": "spark.sql(\"CREATE DATABASE testing\")",
			"metadata": {
				"trusted": true
			},
			"execution_count": 9,
			"outputs": [
				{
					"name": "stdout",
					"text": "DataFrame[]\n",
					"output_type": "stream"
				}
			]
		},
		{
			"cell_type": "code",
			"source": "deltaTable = DeltaTable.forPath(spark, \"s3://aws-analytics-course/temp/store_orders\")\ndeltaTable.generate(\"symlink_format_manifest\")",
			"metadata": {
				"trusted": true
			},
			"execution_count": 4,
			"outputs": [
				{
					"name": "stdout",
					"text": "\n",
					"output_type": "stream"
				}
			]
		},
		{
			"cell_type": "code",
			"source": "spark.sql(\"CREATE  EXTERNAL TABLE IF NOT EXISTS default.store_orders (order_number string, customer_id string, product_id string, order_date string, units string, sale_price string, currency string, order_mode string, updated_at string) ROW FORMAT SERDE 'org.apache.hadoop.hive.ql.io.parquet.serde.ParquetHiveSerDe'  STORED AS INPUTFORMAT 'org.apache.hadoop.hive.ql.io.SymlinkTextInputFormat' OUTPUTFORMAT 'org.apache.hadoop.hive.ql.io.HiveIgnoreKeyTextOutputFormat' LOCATION  's3://aws-analytics-course/temp/store_orders/_symlink_format_manifest/' \")",
			"metadata": {
				"trusted": true
			},
			"execution_count": 8,
			"outputs": [
				{
					"name": "stdout",
					"text": "DataFrame[]\n",
					"output_type": "stream"
				}
			]
		},
		{
			"cell_type": "code",
			"source": "\ndf1=spark.read.format(\"delta\").load(\"s3://aws-analytics-course/temp/store_orders\").show()",
			"metadata": {
				"trusted": true
			},
			"execution_count": 38,
			"outputs": [
				{
					"name": "stdout",
					"text": "+---+---+----+---+----------+---+-----+---+---+-------------------+\n|_c0|_c1| _c2|_c3|       _c4|_c5|  _c6|_c7|_c8|                _c9|\n+---+---+----+---+----------+---+-----+---+---+-------------------+\n|  I|  1| 212|  5|02/03/2019| 10|11.60|USD|NEW|2023-01-10 15:16:52|\n|  I|  2|1940| 10|06/24/2020|  8|72.31|USD|NEW|2023-01-10 15:16:52|\n|  I|  3|  60|  6|02/11/2019|  4|24.82|INR|NEW|2023-01-10 15:16:52|\n|  I|  4|2776|  6|05/20/2018|  4|20.91|USD|NEW|2023-01-10 15:16:52|\n|  I|  5| 409|  9|07/05/2019|  5|98.41|INR|NEW|2023-01-10 15:16:52|\n|  I|  6| 978|  6|12/16/2020|  1| 6.90|USD|NEW|2023-01-10 15:16:52|\n|  I|  7|2904|  6|01/04/2021|  1|71.56|EUR|NEW|2023-01-10 15:16:52|\n|  I|  8|1269|  3|08/11/2018|  6|47.67|USD|NEW|2023-01-10 15:16:52|\n|  I|  9|2628|  5|01/16/2017|  1|59.05|EUR|NEW|2023-01-10 15:16:52|\n|  I| 10|1672|  8|08/01/2020|  3|43.42|USD|NEW|2023-01-10 15:16:52|\n|  I| 11|2666|  5|05/25/2018|  5|43.98|EUR|NEW|2023-01-10 15:16:52|\n|  I| 12|1521|  9|02/21/2019|  1| 9.70|EUR|NEW|2023-01-10 15:16:52|\n|  I| 13|2681|  1|05/12/2017|  3| 7.69|CAD|NEW|2023-01-10 15:16:52|\n|  I| 14|1485|  3|07/21/2020|  3|38.58|EUR|NEW|2023-01-10 15:16:52|\n|  I| 15|2550|  6|08/14/2020|  4| 5.51|CAD|NEW|2023-01-10 15:16:52|\n|  I| 16| 259|  7|07/04/2017|  1|71.70|USD|NEW|2023-01-10 15:16:52|\n|  I| 17|1143|  1|10/31/2017|  5| 0.32|EUR|NEW|2023-01-10 15:16:52|\n|  I| 18| 185|  2|10/25/2017|  3|98.92|USD|NEW|2023-01-10 15:16:52|\n|  I| 19|1819|  2|02/26/2021|  2|52.88|CAD|NEW|2023-01-10 15:16:52|\n|  I| 20| 110|  1|08/31/2020|  7|39.11|INR|NEW|2023-01-10 15:16:52|\n+---+---+----+---+----------+---+-----+---+---+-------------------+\nonly showing top 20 rows\n",
					"output_type": "stream"
				}
			]
		},
		{
			"cell_type": "code",
			"source": "",
			"metadata": {},
			"execution_count": null,
			"outputs": []
		}
	]
}