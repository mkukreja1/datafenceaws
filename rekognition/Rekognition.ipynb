{
	"metadata": {
		"kernelspec": {
			"name": "glue_pyspark",
			"display_name": "Glue PySpark",
			"language": "python"
		},
		"language_info": {
			"name": "Python_Glue_Session",
			"mimetype": "text/x-python",
			"codemirror_mode": {
				"name": "python",
				"version": 3
			},
			"pygments_lexer": "python3",
			"file_extension": ".py"
		}
	},
	"nbformat_minor": 4,
	"nbformat": 4,
	"cells": [
		{
			"cell_type": "code",
			"source": "# ------------------------------------------------------------------------------------------------------------------\n# Amazon Rekognition is a service that makes it easy to add powerful visual analysis to your applications. \n# Rekognition Image lets you easily build powerful applications to search, verify, and organize millions of images. \n# Rekognition Video lets you extract motion-based context from stored or live stream videos and helps you analyze them.\n# Rekognition detects objects, scenes, and faces; extracts text; recognizes celebrities; and identifies inappropriate \n# content in images. It also allows you to search and compare faces. Rekognition Image is based on the same proven, \n# highly scalable, deep learning technology developed by Amazonâs computer vision scientists to analyze billions of \n# images daily for Prime Photos.\n# ------------------------------------------------------------------------------------------------------------------",
			"metadata": {},
			"execution_count": null,
			"outputs": []
		},
		{
			"cell_type": "code",
			"source": "# -------------------------------------------------------------------------\n# Import Python Libraries. Press run.\n# -------------------------------------------------------------------------\n\nfrom pyspark.context import SparkContext\nimport boto3\nimport requests\nimport uuid",
			"metadata": {
				"trusted": true
			},
			"execution_count": null,
			"outputs": []
		},
		{
			"cell_type": "code",
			"source": "# -------------------------------------------------------------------------------------\n# Create the Spark Context and a boto3 client for accessing rekognition API's, Press run.\n# -------------------------------------------------------------------------------------\n\nsc = SparkContext.getOrCreate()\nclient = boto3.client('rekognition', region_name='us-east-1')\n\nBUCKET='aws-analytics-course'",
			"metadata": {
				"trusted": true
			},
			"execution_count": null,
			"outputs": []
		},
		{
			"cell_type": "code",
			"source": "# --------------------------------------------------------------------------------------\n# Lets perform a simple Rekognition. I have placed an image of a dog on S3. The dog\n# is a Labrador Retriever. Let's see how Rekognition describes this image. Press run.\n# --------------------------------------------------------------------------------------\n\nphoto='temp/rekognition/images/dog.jpg'\n\nresponse = client.detect_labels(Image={'S3Object':{'Bucket':BUCKET,'Name':photo}}, MaxLabels=10)\n\nfor label in response['Labels']:\n    print (\"Label: \" + label['Name'])\n    print (\"Confidence: \" + str(label['Confidence']))",
			"metadata": {
				"trusted": true
			},
			"execution_count": null,
			"outputs": []
		},
		{
			"cell_type": "code",
			"source": "# --------------------------------------------------------------------------------------\n# Note the labels attached to the image. A label is an object, scene, or concept found in \n# an image based on its contents.\n# Also note the confidence for each lable. A confidence score is a number between 0 and 100 \n# that indicates the probability that a given prediction is correct.\n# Highlight next cell and Press run.\n# --------------------------------------------------------------------------------------",
			"metadata": {},
			"execution_count": null,
			"outputs": []
		},
		{
			"cell_type": "code",
			"source": "# --------------------------------------------------------------------------------------\n# Lets perform another Rekognition. This time the image is of police officer standing in\n# outside the subway station under a street sign.\n# Highlight next cell and Press run.\n# --------------------------------------------------------------------------------------",
			"metadata": {},
			"execution_count": null,
			"outputs": []
		},
		{
			"cell_type": "code",
			"source": "photo='temp/rekognition/images/police-sign.jpg'\n\nresponse = client.detect_labels(Image={'S3Object':{'Bucket':BUCKET,'Name':photo}}, MaxLabels=10)\n\nfor label in response['Labels']:\n    print (\"Label: \" + label['Name'])\n    print (\"Confidence: \" + str(label['Confidence']))",
			"metadata": {
				"trusted": true
			},
			"execution_count": null,
			"outputs": []
		},
		{
			"cell_type": "code",
			"source": "# ----------------------------------------------------------------------------------------------------------\n# How cool it would be if the street sign could be read as text. Imagine the possibilities that\n# could open up. Text in Image is a capability of Amazon Rekognition that allows you to detect and recognize \n# text within an image, such as street names, captions, product names, and vehicular license plates.\n# Highlight next cell and Press run.\n# ----------------------------------------------------------------------------------------------------------",
			"metadata": {},
			"execution_count": null,
			"outputs": []
		},
		{
			"cell_type": "code",
			"source": "photo='temp/rekognition/images/police-sign.jpg'\n\nresponse = client.detect_text(Image={'S3Object':{'Bucket':BUCKET,'Name':photo}})\n\ntextDetections=response['TextDetections']\nprint ('Detected text')\nfor text in textDetections:\n    print ('Detected text:' + text['DetectedText'])\n    print ('Confidence: ' + \"{:.2f}\".format(text['Confidence']) + \"%\")\n    print ('Id: {}'.format(text['Id']))\n    if 'ParentId' in text:\n        print ('Parent Id: {}'.format(text['ParentId']))\n    print ('Type:' + text['Type'])\n    print",
			"metadata": {
				"trusted": true
			},
			"execution_count": null,
			"outputs": []
		},
		{
			"cell_type": "code",
			"source": "# ----------------------------------------------------------------------------------------------------------\n# Notice the Detected Text fields above. Rekognition correctly detected the text from the street sign as\n# 90 Saint.Eimhurst Av.. It also recognized another piece of text from a yellow parking lot sign.\n# Highlight next cell and Press run.\n# ----------------------------------------------------------------------------------------------------------",
			"metadata": {},
			"execution_count": null,
			"outputs": []
		},
		{
			"cell_type": "code",
			"source": "# ----------------------------------------------------------------------------------------------------------\n# Amazon Rekognitionâs Celebrity Recognition is a deep learning based easy-to-use API for detection and \n# recognition of individuals who are famous, noteworthy, or prominent in their field. Let's see how Celebrity \n# Recognition works.\n# Highlight next cell and Press run.\n# ----------------------------------------------------------------------------------------------------------",
			"metadata": {},
			"execution_count": null,
			"outputs": []
		},
		{
			"cell_type": "code",
			"source": "response = requests.get('https://upload.wikimedia.org/wikipedia/commons/thumb/a/a8/Bill_Gates_2017_%28cropped%29.jpg/220px-Bill_Gates_2017_%28cropped%29.jpg')\nresponse_content = response.content\n\nrekognition_response = client.recognize_celebrities(Image={'Bytes': response_content})\n\nprint(rekognition_response)",
			"metadata": {
				"trusted": true
			},
			"execution_count": null,
			"outputs": []
		},
		{
			"cell_type": "code",
			"source": "# ----------------------------------------------------------------------------------------------------------\n# Notice the Name tag in the output above. The image was correctly identified as famous physicist Stephen Hawking.\n# Highlight next cell and Press run.\n# ----------------------------------------------------------------------------------------------------------",
			"metadata": {},
			"execution_count": null,
			"outputs": []
		},
		{
			"cell_type": "code",
			"source": "url='https://upload.wikimedia.org/wikipedia/commons/thumb/6/6e/Shah_Rukh_Khan_graces_the_launch_of_the_new_Santro.jpg/220px-Shah_Rukh_Khan_graces_the_launch_of_the_new_Santro.jpg'\n    \nresponse = requests.get(url)\nresponse_content = response.content\n\nrekognition_response = client.recognize_celebrities(Image={'Bytes': response_content})\n\nprint(rekognition_response)",
			"metadata": {
				"trusted": true
			},
			"execution_count": null,
			"outputs": []
		},
		{
			"cell_type": "code",
			"source": "# ----------------------------------------------------------------------------------------------------------\n# This time the image was correctly identified as famous actor Shahrukh Khan.\n# Highlight next cell and Press run.\n# ----------------------------------------------------------------------------------------------------------",
			"metadata": {},
			"execution_count": null,
			"outputs": []
		},
		{
			"cell_type": "code",
			"source": "# ----------------------------------------------------------------------------------------------------------\n# Can Amazon Rekognition compare faces? It can. Face Comparison is the process of comparing one face to one \n# or more faces to measure similarity. I have uploaded 2 images of Tiger Woods for comparison. Let's see \n# how these faces compare.\n# Highlight next cell and Press run.\n# ----------------------------------------------------------------------------------------------------------",
			"metadata": {},
			"execution_count": null,
			"outputs": []
		},
		{
			"cell_type": "code",
			"source": "KEY_SOURCE = \"temp/rekognition/images/tiger1.jpg\"\nKEY_TARGET = \"temp/rekognition/images/tiger2.jpg\"\n\ndef compare_faces(bucket, key, bucket_target, key_target, threshold=80, region=\"us-east-1\"):\n    rekognition = boto3.client(\"rekognition\", region)\n    response = client.compare_faces(\n    SourceImage={\n          \"S3Object\": {\n          \"Bucket\": bucket,\n          \"Name\": key,\n          }\n        },\n        TargetImage={\n           \"S3Object\": {\n           \"Bucket\": bucket_target,\n           \"Name\": key_target,\n           }\n        },\n        SimilarityThreshold=threshold,\n        )\n    return response['SourceImageFace'], response['FaceMatches']\n\n\nsource_face, matches = compare_faces(BUCKET, KEY_SOURCE, BUCKET, KEY_TARGET)\n\n# the main source face\nprint(\"Source Face ({Confidence}%)\".format(**source_face))\n#print \"matches: \"+str(matches)\n\n# one match for each target face\nfor match in matches:\n    print(\"Target Face ({Confidence}%)\".format(**match['Face']))\n    print(\"  Similarity : {}%\".format(match['Similarity']))\n",
			"metadata": {
				"trusted": true
			},
			"execution_count": null,
			"outputs": []
		},
		{
			"cell_type": "code",
			"source": "# ----------------------------------------------------------------------------------------------------------\n# Amazon Rekognition compared the faces and came to the conclusion that the two images are a perfect match \n# of Tiger Woods.\n# Highlight next cell and Press run.\n# ----------------------------------------------------------------------------------------------------------",
			"metadata": {},
			"execution_count": null,
			"outputs": []
		},
		{
			"cell_type": "code",
			"source": "# ----------------------------------------------------------------------------------------------------------\n# This time lets compare Tiger Woods to a Tiger Woods look alike.\n# I have uploaded the image of Tiger Woods and his look alike for comparison. Let's see \n# how these faces compare.\n# Highlight next cell and Press run.\n# ----------------------------------------------------------------------------------------------------------",
			"metadata": {},
			"execution_count": null,
			"outputs": []
		},
		{
			"cell_type": "code",
			"source": "KEY_SOURCE = \"temp/rekognition/images/tiger1.jpg\"\nKEY_TARGET = \"temp/rekognition/images/tiger_not.jpg\"\n\ndef compare_faces(bucket, key, bucket_target, key_target, threshold=80, region=\"eu-west-1\"):\n    rekognition = boto3.client(\"rekognition\", region)\n    response = client.compare_faces(\n    SourceImage={\n          \"S3Object\": {\n          \"Bucket\": bucket,\n          \"Name\": key,\n          }\n        },\n        TargetImage={\n           \"S3Object\": {\n           \"Bucket\": bucket_target,\n           \"Name\": key_target,\n           }\n        },\n        SimilarityThreshold=threshold,\n        )\n    return response['SourceImageFace'], response['FaceMatches']\n\n\nsource_face, matches = compare_faces(BUCKET, KEY_SOURCE, BUCKET, KEY_TARGET)\n\n# the main source face\n#print \"Source Face ({Confidence}%)\".format(**source_face)\nif not matches:\n    print(\"Not a Match\")\n\n\n# one match for each target face\nfor match in matches:\n    print(\"Target Face ({Confidence}%)\".format(**match['Face']))\n    print(\"  Similarity : {}%\".format(match['Similarity']))\n",
			"metadata": {
				"trusted": true
			},
			"execution_count": null,
			"outputs": []
		},
		{
			"cell_type": "code",
			"source": "# ----------------------------------------------------------------------------------------------------------\n# It's not a match!!\n# Highlight next cell and Press run.\n# ----------------------------------------------------------------------------------------------------------",
			"metadata": {},
			"execution_count": null,
			"outputs": []
		},
		{
			"cell_type": "code",
			"source": "COLLECTION = \"rek-collection-1\"\nclient.create_collection(CollectionId=COLLECTION)\nclient.list_collections()",
			"metadata": {
				"trusted": true
			},
			"execution_count": null,
			"outputs": []
		},
		{
			"cell_type": "code",
			"source": "# ----------------------------------------------------------------------------------------------------------\n# Amazon Rekognition can store information about detected faces in server-side containers known as collections. \n# You can use the facial information that's stored in a collection to search for known faces in images, stored \n# videos, and streaming videos. Let' store the image of Tiger Woods in a new collection.\n# Highlight next cell and Press run.\n# ----------------------------------------------------------------------------------------------------------",
			"metadata": {},
			"execution_count": null,
			"outputs": []
		},
		{
			"cell_type": "code",
			"source": "KEY = \"temp/rekognition/images/tiger1.jpg\"\nIMAGE_ID = uuid.uuid4().hex  \n\n# Note: you have to create the collection first!\n#client.create_collection(CollectionId=COLLECTION)\n\ndef index_faces(bucket, key, collection_id, image_id=None, attributes=(), region=\"us-east-1\"):\n\n    response = client.index_faces(\n                                 Image={\n                                 \"S3Object\": {\n                                 \"Bucket\": bucket,\n                                 \"Name\": key,\n                                 }\n                                 },\n                                 CollectionId=collection_id,\n                                 ExternalImageId=image_id,\n                                     DetectionAttributes=attributes,\n                                 )\n    return response['FaceRecords']\n\n\nfor record in index_faces(BUCKET, KEY, COLLECTION, IMAGE_ID):\n    face = record['Face']\n    # details = record['FaceDetail']\n    print(\"Face ({}%)\".format(face['Confidence']))\n    print(\"  FaceId: {}\".format(face['FaceId']))\n    print(\"  ImageId: {}\".format(face['ImageId']))\n",
			"metadata": {
				"trusted": true
			},
			"execution_count": null,
			"outputs": []
		},
		{
			"cell_type": "code",
			"source": "# ----------------------------------------------------------------------------------------------------------\n# Now let's search for Tiger Woods in our collections database using a completely new picture.\n# Highlight next cell and Press run.\n# ----------------------------------------------------------------------------------------------------------",
			"metadata": {},
			"execution_count": null,
			"outputs": []
		},
		{
			"cell_type": "code",
			"source": "KEY = \"temp/rekognition/images/search_tiger.jpg\"\n\ndef search_faces_by_image(bucket, key, collection_id, threshold=80, region=\"eu-west-1\"):\n    response = client.search_faces_by_image(\n                         Image={\n                         \"S3Object\": {\n                         \"Bucket\": bucket,\n                         \"Name\": key,\n                         }\n                         },\n                         CollectionId=collection_id,\n                         FaceMatchThreshold=threshold,\n                         )\n    return response['FaceMatches']\n\nfor record in search_faces_by_image(BUCKET, KEY, COLLECTION):\n        face = record['Face']\n        print(\"Matched Face ({}%)\".format(record['Similarity']))",
			"metadata": {
				"trusted": true
			},
			"execution_count": null,
			"outputs": []
		},
		{
			"cell_type": "code",
			"source": "# ----------------------------------------------------------------------------------------------------------\n# Looks like the picture matched. Comparing faces within collections goes a long way in Master Data \n# Management  initiatives.\n# Highlight next cell and Press run.\n# ----------------------------------------------------------------------------------------------------------",
			"metadata": {},
			"execution_count": null,
			"outputs": []
		},
		{
			"cell_type": "code",
			"source": "# ----------------------------------------------------------------------------------------------------------\n# Now let's search for Will Smith in our collections database.\n# Highlight next cell and Press run.\n# ----------------------------------------------------------------------------------------------------------",
			"metadata": {},
			"execution_count": null,
			"outputs": []
		},
		{
			"cell_type": "code",
			"source": "KEY = \"temp/rekognition/images/will.jpg\"\n\ndef search_faces_by_image(bucket, key, collection_id, threshold=80, region=\"eu-west-1\"):\n    response = client.search_faces_by_image(\n                 Image={\n                      \"S3Object\": {\n                      \"Bucket\": bucket,\n                      \"Name\": key,\n                 }\n                 },\n                 CollectionId=collection_id,\n                 FaceMatchThreshold=threshold,\n                 )\n    return response['FaceMatches']\n\nfor record in search_faces_by_image(BUCKET, KEY, COLLECTION):\n        face = record['Face']\n        print(\"Matched Face ({}%)\".format(record['Similarity']))\n        print(\"  FaceId : {}\".format(face['FaceId']))\n        print(\"  ImageId : {}\".format(face['ExternalImageId']))\nelse:\n    print('Image not in our database')",
			"metadata": {
				"trusted": true
			},
			"execution_count": null,
			"outputs": []
		},
		{
			"cell_type": "code",
			"source": "# ----------------------------------------------------------------------------------------------------------\n# Will Smith does not exist in our collections database.\n# Highlight next cell and Press run.\n# ----------------------------------------------------------------------------------------------------------",
			"metadata": {},
			"execution_count": null,
			"outputs": []
		},
		{
			"cell_type": "code",
			"source": "client.delete_collection(CollectionId=COLLECTION)\nclient.list_collections()",
			"metadata": {
				"trusted": true
			},
			"execution_count": null,
			"outputs": []
		},
		{
			"cell_type": "code",
			"source": "# ----------------------------------------------------------------------------------------------------------\n# How can object detection within an image be useful? Imagine a security camera captured a man with a gun in a\n# busy mall. Image labels can be read by Data Science/Monitoring Algorithms and proper authorities could be \n# alerted before a mishap happens. \n# Highlight next cell and Press run.\n# ----------------------------------------------------------------------------------------------------------",
			"metadata": {},
			"execution_count": null,
			"outputs": []
		},
		{
			"cell_type": "code",
			"source": "photo='temp/rekognition/images/pistol.jpg'\n\nresponse = client.detect_labels(Image={'S3Object':{'Bucket':BUCKET,'Name':photo}}, MaxLabels=10)\n\nfor label in response['Labels']:\n    print (\"Label: \" + label['Name'])\n    print (\"Confidence: \" + str(label['Confidence']))",
			"metadata": {
				"trusted": true
			},
			"execution_count": null,
			"outputs": []
		},
		{
			"cell_type": "code",
			"source": "# ----------------------------------------------------------------------------------------------------------\n# The possibilities are endless. Everyday many large scale organizations are finding new ways to use this \n# technology. I hope you found this information both informative and useful. Amazon \n# Rekognition is covered in more detail in the AWS Data Analytics Speciality training. \n# ----------------------------------------------------------------------------------------------------------",
			"metadata": {},
			"execution_count": null,
			"outputs": []
		}
	]
}